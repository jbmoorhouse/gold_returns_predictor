{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAUUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xau_ratios = [\n",
    "    \"WGC/GOLD_DAILY_USD\"\n",
    "#     \"WGC/GOLD_DAILY_EUR\",\n",
    "#     \"WGC/GOLD_DAILY_TRY\",\n",
    "#     \"WGC/GOLD_DAILY_JPY\",\n",
    "#     \"WGC/GOLD_DAILY_GBP\",\n",
    "#     \"WGC/GOLD_DAILY_CAD\",\n",
    "#     \"WGC/GOLD_DAILY_CHF\",\n",
    "#     \"WGC/GOLD_DAILY_VND\",\n",
    "#     \"WGC/GOLD_DAILY_KRW\",\n",
    "#     \"WGC/GOLD_DAILY_RUB\",\n",
    "#     \"WGC/GOLD_DAILY_AUD\",\n",
    "]\n",
    "\n",
    "economic_indc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quandl data terms\n",
    "\n",
    "Anyone seeking to use this code must first apply for an account with [Quandl](https://www.quandl.com) in order to receive an valid authetitciation key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_NAME = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "FILEPATH = os.path.join(DIR_NAME, \"auth.txt\")\n",
    "\n",
    "with open(FILEPATH, \"r\") as f:\n",
    "    authtoken = f.read();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.90s/it]\n"
     ]
    }
   ],
   "source": [
    "xau_df_dict = {}\n",
    "\n",
    "\n",
    "for ratio in tqdm(xau_ratios):\n",
    "    name = ratio.lower().replace(\"/\", \"_\")\n",
    "\n",
    "    # get the ratio dataframe\n",
    "    df = quandl.get(ratio, authtoken=authtoken, start_date = \"1979-01-01\")\n",
    "    df.columns = [\"price\"]\n",
    "    \n",
    "    # check for missing business days \n",
    "    if pd.infer_freq(df.index) != \"B\":\n",
    "        logging.warn(\"Datetime frequency is not Business Days\")\n",
    "    \n",
    "    xau_df_dict[name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "annualization_factor = 252.\n",
    "window_size = [5, 20, 60, 120, 252]\n",
    "\n",
    "for ratio, df in tqdm(xau_df_dict.items()):\n",
    "    start_date, end_date = df.index[0], df.index[-1]\n",
    "    full_range = pd.date_range(start_date, end_date, freq = \"B\")\n",
    "    \n",
    "    if not np.array_equal(df.index, pd.date_range(start_date, end_date, freq=\"B\")):\n",
    "        logging.warning(\"\\n{} is missing business days\".format(ratio))\n",
    "\n",
    "    for window in window_size:\n",
    "        df['{}d_market_vol'.format(window)] = np.sqrt(\n",
    "            (annualization_factor/window) * df['price'].rolling(window).var(ddof=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quandl Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"FRED/T10Y2Y\",\n",
    "    \"ML/AAAEY\",\n",
    "    \"ML/CCCY\",\n",
    "    \"RATEINF/INFLATION_USA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "\tFRED/T10Y2Y is missing business days\n",
      "WARNING:root:\n",
      "\tML/AAAEY is missing business days\n",
      "WARNING:root:\n",
      "\tML/CCCY is missing business days\n",
      "WARNING:root:\n",
      "\tRATEINF/INFLATION_USA is missing business days\n"
     ]
    }
   ],
   "source": [
    "for ratio, df in xau_df_dict.items():\n",
    "    for feature in features:\n",
    "        col_name = feature.lower().replace('/', '_')\n",
    "        \n",
    "        # get quandl features. `end_date` is set to df.index[-1] to match the price data\n",
    "        data = quandl.get(feature, authtoken=authtoken, start_date = \"1979-01-01\", end_date = df.index[-1])\n",
    "        start_date, end_date = data.index[0], data.index[-1]\n",
    "\n",
    "        # Some features contain missing data. To best simulate how the data would be ingested\n",
    "        # realtime, the current value is forward filled. This achieved by resampling.\n",
    "        if not np.array_equal(data.index, pd.date_range(start_date, end_date, freq=\"B\")):\n",
    "            logging.warning(\"\\n\\t{} is missing business days\".format(feature))\n",
    "                    \n",
    "        df[col_name] = data\n",
    "    \n",
    "    df[:] = df.ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical indicator features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "\n",
    "technical_indicators= {\n",
    "    \"MACD\" : (\"macd\", \"macdsignal\", \"macdhist\"),\n",
    "    \"STOCHRSI\" : (\"fastk\", \"fastd\"),\n",
    "    \"MOM\" : (\"real\")\n",
    "}\n",
    "\n",
    "for ratio, df in xau_df_dict.items():\n",
    "    \n",
    "    # talib requires market price data. starting price of $1 is taken\n",
    "    # since absolute values are not important (preprocess scaling)\n",
    "    price = df['price'].values\n",
    "\n",
    "    for indicator, indicator_type in technical_indicators.items():\n",
    "        # Return the result for each indicator\n",
    "        result = getattr(talib, indicator)(price)\n",
    "\n",
    "        if isinstance(result, np.ndarray):\n",
    "            df[indicator.lower()] = result\n",
    "        else:\n",
    "            for f, r in zip(indicator_type, result):\n",
    "                df[\"{}_{}\".format(indicator.lower(), f)] = r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns which specific `fillna` criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ratio, df in xau_df_dict.items():\n",
    "    fill_na_cols = ['ml_aaaey', 'ml_cccy']\n",
    "    \n",
    "    # fillna using a dictionary of average values\n",
    "    df[fill_na_cols] = df[fill_na_cols].fillna(df[fill_na_cols].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preporocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split(all_x, all_y, train_size, valid_size, test_size):\n",
    "    \"\"\"\n",
    "    Generate the train, validation, and test dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_x : DataFrame\n",
    "        All the input samples\n",
    "    all_y : Pandas Series\n",
    "        All the target values\n",
    "    train_size : float\n",
    "        The proportion of the data used for the training dataset\n",
    "    valid_size : float\n",
    "        The proportion of the data used for the validation dataset\n",
    "    test_size : float\n",
    "        The proportion of the data used for the test dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_train : DataFrame\n",
    "        The train input samples\n",
    "    x_valid : DataFrame\n",
    "        The validation input samples\n",
    "    x_test : DataFrame\n",
    "        The test input samples\n",
    "    y_train : Pandas Series\n",
    "        The train target values\n",
    "    y_valid : Pandas Series\n",
    "        The validation target values\n",
    "    y_test : Pandas Series\n",
    "        The test target values\n",
    "    \"\"\"\n",
    "    \n",
    "    assert train_size > 0 and train_size < 1.0\n",
    "    assert valid_size > 0 and valid_size < 1.0\n",
    "    assert test_size > 0 and test_size < 1.0\n",
    "    assert train_size + valid_size + test_size == 1.0\n",
    "    \n",
    "    dates = all_x.index\n",
    "    \n",
    "    train_dates, valid_dates, test_dates = np.split(\n",
    "        dates, [int(len(dates) * train_size), \n",
    "                int(len(dates) * (train_size + test_size))]\n",
    "    )\n",
    "    \n",
    "    X_train = all_x.loc[train_dates, :]\n",
    "    X_valid = all_x.loc[valid_dates, :]\n",
    "    X_test = all_x.loc[test_dates, :]\n",
    "    \n",
    "    y_train = all_y.loc[train_dates]\n",
    "    y_valid = all_y.loc[valid_dates]\n",
    "    y_test = all_y.loc[test_dates]\n",
    "    \n",
    "    return {\n",
    "        \"X_train\" : X_train, \n",
    "        \"X_valid\" : X_valid, \n",
    "        \"X_test\" : X_test, \n",
    "        \"y_train\" : y_train, \n",
    "        \"y_valid\" : y_valid, \n",
    "        \"y_test\" : y_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xau_df_dict['wgc_gold_daily_usd']\n",
    "data['target'] = df['price'].shift(-1).pct_change()\n",
    "data.dropna(inplace = True)\n",
    "\n",
    "X = data.drop(['price', 'target'], axis = 1)\n",
    "y = data['target']\n",
    "               \n",
    "split_data = train_valid_test_split(X, y, 0.7, 0.15, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "scalar.fit(split_data[\"X_train\"])\n",
    "\n",
    "scaled_split_data = {name : scalar.transform(df) if \"X\" in name else df for name, df in split_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = scaled_split_data['X_train'].shape[0]\n",
    "n_features = scaled_split_data['X_train'].shape[1]\n",
    "\n",
    "clf_parameters = {\n",
    "    'criterion': 'entropy',\n",
    "    'min_samples_leaf': 10,\n",
    "    'oob_score': True,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 0}\n",
    "\n",
    "n_trees_l = [30, 100, 250, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "valid_score = []\n",
    "oob_score = []\n",
    "feature_importances = []\n",
    "\n",
    "for n_trees in tqdm(n_trees_l, desc='Training Models', unit='Model'):\n",
    "    \n",
    "    clf = RandomForestClassifier(n_trees, **clf_parameters)\n",
    "    clf.fit(scaled_split_data['X_train'], scaled_split_data[\"y_train\"])\n",
    "    \n",
    "    train_score.append(clf.score(scaled_split_data['X_train'], scaled_split_data[\"y_train\"].values))\n",
    "    valid_score.append(clf.score(scaled_split_data[\"X_valid\"], scaled_split_data[\"y_valid\"].values))\n",
    "    \n",
    "    oob_score.append(clf.oob_score_)\n",
    "    feature_importances.append(clf.feature_importances_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
