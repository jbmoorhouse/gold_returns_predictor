{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAUUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# scikit-learn modules\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# User defined modules\n",
    "from column_transformers.technical_indicators import MacdSignal, StochRsiSignal\n",
    "from column_transformers.dates import DateDummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xau_ratios = [\n",
    "    \"WGC/GOLD_DAILY_USD\"\n",
    "#     \"WGC/GOLD_DAILY_EUR\",\n",
    "#     \"WGC/GOLD_DAILY_TRY\",\n",
    "#     \"WGC/GOLD_DAILY_JPY\",\n",
    "#     \"WGC/GOLD_DAILY_GBP\",\n",
    "#     \"WGC/GOLD_DAILY_CAD\",\n",
    "#     \"WGC/GOLD_DAILY_CHF\",\n",
    "#     \"WGC/GOLD_DAILY_VND\",\n",
    "#     \"WGC/GOLD_DAILY_KRW\",\n",
    "#     \"WGC/GOLD_DAILY_RUB\",\n",
    "#     \"WGC/GOLD_DAILY_AUD\",\n",
    "]\n",
    "\n",
    "economic_indc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quandl data terms\n",
    "\n",
    "Anyone seeking to use this code must first apply for an account with [Quandl](https://www.quandl.com) in order to receive an valid authetitciation key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_NAME = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "FILEPATH = os.path.join(DIR_NAME, \"auth.txt\")\n",
    "\n",
    "with open(FILEPATH, \"r\") as f:\n",
    "    authtoken = f.read();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "xau_df_dict = {}\n",
    "\n",
    "for ratio in tqdm(xau_ratios):\n",
    "    name = ratio.lower().replace(\"/\", \"_\")\n",
    "\n",
    "    # get the ratio dataframe\n",
    "    df = quandl.get(ratio, authtoken=authtoken, start_date = \"1979-01-01\")\n",
    "    df.columns = [\"price\"]\n",
    "    \n",
    "    # check for missing business days \n",
    "    if pd.infer_freq(df.index) != \"B\":\n",
    "        logging.warn(\"Datetime frequency is not Business Days\")\n",
    "    \n",
    "    xau_df_dict[name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "annualization_factor = 252.\n",
    "window_size = [5, 10, 20, 60, 120]\n",
    "\n",
    "for ratio, df in tqdm(xau_df_dict.items()):\n",
    "    start_date, end_date = df.index[0], df.index[-1]\n",
    "    full_range = pd.date_range(start_date, end_date, freq = \"B\")\n",
    "    \n",
    "    if not np.array_equal(df.index, pd.date_range(start_date, end_date, freq=\"B\")):\n",
    "        logging.warning(\"\\n{} is missing business days\".format(ratio))\n",
    "\n",
    "    for window in window_size:\n",
    "        df['{}d_market_vol'.format(window)] = np.sqrt(\n",
    "            (annualization_factor/window) * df['price'].rolling(window).var(ddof=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quandl Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"FRED/T10Y2Y\",\n",
    "    \"RATEINF/INFLATION_USA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "\tFRED/T10Y2Y is missing business days\n",
      "WARNING:root:\n",
      "\tRATEINF/INFLATION_USA is missing business days\n"
     ]
    }
   ],
   "source": [
    "for ratio, df in xau_df_dict.items():\n",
    "    for feature in features:\n",
    "        col_name = feature.lower().replace('/', '_')\n",
    "        \n",
    "        # get quandl features. `end_date` is set to df.index[-1] to match the price data\n",
    "        data = quandl.get(feature, authtoken=authtoken, start_date = \"1979-01-01\", end_date = df.index[-1])\n",
    "        start_date, end_date = data.index[0], data.index[-1]\n",
    "\n",
    "        # Some features contain missing data. To best simulate how the data would be ingested\n",
    "        # realtime, the current value is forward filled. This achieved by resampling.\n",
    "        if not np.array_equal(data.index, pd.date_range(start_date, end_date, freq=\"B\")):\n",
    "            logging.warning(\"\\n\\t{} is missing business days\".format(feature))\n",
    "                    \n",
    "        df[col_name] = data\n",
    "    \n",
    "    df[:] = df.ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical indicator features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "\n",
    "technical_indicators= {\n",
    "    \"MACD\" : (\"macd\", \"macdsignal\", \"macdhist\"),\n",
    "    \"STOCHRSI\" : (\"fastk\", \"fastd\"),\n",
    "    \"MOM\" : (\"real\"),\n",
    "    \"APO\" : ('real'),\n",
    "    \"RSI\" : ('real')\n",
    "}\n",
    "\n",
    "for ratio, df in xau_df_dict.items():\n",
    "    \n",
    "    # talib requires market price data. starting price of $1 is taken\n",
    "    # since absolute values are not important (preprocess scaling)\n",
    "    price = df['price'].values\n",
    "\n",
    "    for indicator, indicator_type in technical_indicators.items():\n",
    "        # Return the result for each indicator\n",
    "        if indicator == 'STOCHRSI':\n",
    "            result = getattr(talib, indicator)(price, fastd_matype = 8)\n",
    "        else:\n",
    "            result = getattr(talib, indicator)(price)\n",
    "\n",
    "        if isinstance(result, np.ndarray):\n",
    "            df[indicator.lower()] = result\n",
    "        else:\n",
    "            for f, r in zip(indicator_type, result):\n",
    "                if f == indicator.lower():\n",
    "                    df[\"{}\".format(indicator.lower())] = r\n",
    "                else:\n",
    "                    df[\"{}_{}\".format(indicator.lower(), f)] = r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split._split import TrainValidateTest\n",
    "\n",
    "data = xau_df_dict['wgc_gold_daily_usd']\n",
    "data['target'] = data['price'].shift(-1).pct_change()\n",
    "data.dropna(inplace = True)\n",
    "\n",
    "X = data.drop(['price', 'target'], axis = 1)\n",
    "y = (data['target'] > 0).astype(int)\n",
    "    \n",
    "split = TrainValidateTest(0.7, 0.15, 0.15)\n",
    "X_train, X_valid,  X_test, y_train, y_valid,  y_test = split.transform(X, y)\n",
    "\n",
    "\n",
    "df = data.loc['1980':'1981', ['price', 'macd', 'macd_macdsignal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'colname' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-cd9fa05d32fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmacd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMacdStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmacd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxau_df_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wgc_gold_daily_usd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/Joseph Moorhouse/Google Drive/Joseph Moorhouse/EBB Holdings/Strategy_Analysis/02_xau/column_transformers/alpha_factors.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# ======================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/Joseph Moorhouse/Google Drive/Joseph Moorhouse/EBB Holdings/Strategy_Analysis/02_xau/column_transformers/alpha_factors.py\u001b[0m in \u001b[0;36m_macd\u001b[0;34m(self, X, col_name)\u001b[0m\n\u001b[1;32m     86\u001b[0m             return X.assign(\n\u001b[1;32m     87\u001b[0m                 \u001b[0mmacd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmacd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mmacd_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmacd_signal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0mmacdhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmacd_hist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'colname' is not defined"
     ]
    }
   ],
   "source": [
    "from column_transformers.alpha_factors import MacdStrategy\n",
    "    \n",
    "macd = MacdStrategy()\n",
    "d = macd.transform(xau_df_dict['wgc_gold_daily_usd']['price'])\n",
    "\n",
    "d.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.loc[:, ['price', 'macd', 'macd_macdsignal']]\n",
    "\n",
    "# Calculate the returns\n",
    "df['returns'] = df['price'].pct_change()\n",
    "\n",
    "# long/short periods ignoring lookahead bias\n",
    "long_biased = df['macd'] >= df['macd_macdsignal']\n",
    "short_biased = (df['macd'] <= df['macd_macdsignal'])\n",
    "\n",
    "# Define long entry and exit points\n",
    "long_entry = (df['macd'].shift(1) > df['macd_macdsignal'].shift(1)) #& (df['macd'].diff() > 0 & (df['macd'].diff().shift(1) < 0))\n",
    "#cross_over_long_exit = (df['macd'] < df['macd_macdsignal']) & (df['macd'].shift(1) > df['macd_macdsignal'].shift(1))\n",
    "#omentum_long_exit = (df['macd'].diff() >= 0) & (df['macd'].diff().shift(1) <= 0)\n",
    "\n",
    "# Define short entry and exit points\n",
    "short_entry = (df['macd'].shift(1) < df['macd_macdsignal'].shift(1)) & ((df['macd'].diff().shift(1) < 0))\n",
    "#cross_over_short_exit = (df['macd'] > df['macd_macdsignal']) & (df['macd'].shift(1) < df['macd_macdsignal'].shift(1))\n",
    "#momentum_short_exit = (df['macd'].diff() <= 0) & (df['macd'].diff().shift(1) <= 0)\n",
    "\n",
    "# define simple long/short strategy\n",
    "df['long'] = (long_entry) * 1 # add exit periods back here\n",
    "df['short'] = (short_entry) * -1\n",
    "\n",
    "# long/short periods\n",
    "longs = df.index[df['long'] == 1]\n",
    "shorts = df.index[df['short'] == -1]\n",
    "\n",
    "# start date positions of new long/short positions\n",
    "long_indices_or_sections = np.arange(longs.size)[longs.to_series().diff() > pd.Timedelta('3D')]\n",
    "short_indices_or_sections = np.arange(shorts.size)[shorts.to_series().diff() > pd.Timedelta('3D')]\n",
    "\n",
    "# long/short date regions\n",
    "long_date_regions = np.split(longs, long_indices_or_sections)\n",
    "short_date_regions = np.split(shorts, short_indices_or_sections)\n",
    "\n",
    "\n",
    "df['alpha_return'] = (df['returns'] * df['long']) + (df['returns'] * df['short']) \n",
    "df['gold_perf'] =  (1 + df['returns']).cumprod()\n",
    "df['alpha_perf'] = (1 + df['alpha_return']).cumprod()\n",
    "\n",
    "#df = df.dropna()\n",
    "\n",
    "print((np.sqrt(252.) * df['alpha_return'].mean()) / df['alpha_return'].std())\n",
    "\n",
    "df[['alpha_perf', 'gold_perf']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macd = [\"macd\", \"macdsignal\", \"macdhist\"]\n",
    "d = data.copy()\n",
    "\n",
    "for i in tqdm(range(2, 20)):\n",
    "    for j in range(4, 30):\n",
    "        for k in range(3, 10):\n",
    "            result = talib.MACD(data['price'], fastperiod=i, slowperiod=j, signalperiod=k)\n",
    "            \n",
    "            for ind, r in zip(macd, result):\n",
    "                d['macd_{}_{}_{}_{}'.format(ind, i,j,k)] = r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(16, 10)})\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1)\n",
    "\n",
    "df.loc['1990', 'alpha_perf'].plot(ax = axes[0])\n",
    "df.loc['1990', ['macd', 'macd_macdsignal']].plot(ax=axes[1])\n",
    "df.loc['1990', 'gold_perf'].plot(ax = axes[2])\n",
    "\n",
    "for l_period, s_period in zip(long_date_regions, short_date_regions):\n",
    "    for ax in axes:\n",
    "        ax.axvline(l_period[0], color='green', linewidth=1)\n",
    "        ax.axvline(s_period[0], color='green', linewidth=1)\n",
    "                                             \n",
    "        ax.axvline(l_period[-1], color='red', linewidth=1)\n",
    "        ax.axvline(s_period[-1], color='red', linewidth=1)\n",
    "\n",
    "        ax.axvspan(l_period[0], l_period[-1], alpha = 0.1, color = 'green')\n",
    "        ax.axvspan(s_period[0], s_period[-1], alpha = 0.1, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exit'] = momentum_long_exit\n",
    "\n",
    "\n",
    "a = df[['macd', 'long']]\n",
    "a['diff'] = a['macd'].diff()\n",
    "a['long_entry'] = long_entry\n",
    "\n",
    "#a['exit'] = (a['macd'].diff() >= 0) & (a['macd'].diff().shift(1) <= 0)\n",
    "a['1980-01':'1980-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['price','rsi']]  \n",
    "\n",
    "df.head()\n",
    "\n",
    "#df.loc['2013-05':'2013-09', 'rsi'].plot()\n",
    "\n",
    "rsi_min = df['rsi'].rolling(14).min()\n",
    "rsi_max = df['rsi'].rolling(14).max()\n",
    "\n",
    "((df['rsi'] - rsi_min) / (rsi_max - rsi_min)).rolling(3).mean()['2013'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline = Pipeline([\n",
    "     ('macd_ud_signal', MacdSignal()),\n",
    "     ('stoch_ud_signal', StochRsiSignal()),\n",
    "     #('date', DateDummy('weekday_name', 'month_name')),\n",
    "     #('vol_diff', VolatilityDiff()),\n",
    "     #('scalar', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train_trans, X_valid_trans= (\n",
    "    preprocess_pipeline.fit_transform(X_train),\n",
    "    preprocess_pipeline.transform(X_valid)\n",
    ")\n",
    "\n",
    "X_train_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15, 8)})\n",
    "df = X_train.loc['1981', ['10d_market_vol', '20d_market_vol']]\n",
    "\n",
    "d_20 = df['10d_market_vol']\n",
    "d_60 = df['20d_market_vol']\n",
    "\n",
    "df.plot()\n",
    "\n",
    "dates = (\n",
    "    (d_20 > d_60) & (d_20.shift(-1) < d_60.shift(-1)) |\n",
    "    (d_20 > d_60) & (d_20.shift(1) < d_60.shift(1))\n",
    ")\n",
    "\n",
    "for date in d_20.index[dates]:\n",
    "    plt.axvline(date)\n",
    "    difference = (d_20 -d_60)\n",
    "\n",
    "difference.index[(difference < 0) & (difference.shift(-1) > 0)]\n",
    "difference.plot()\n",
    "\n",
    "xau_df_dict['wgc_gold_daily_usd'].loc['1981', 'price'].plot()\n",
    "for date in d_20.index[dates]:\n",
    "    plt.axvline(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifiers = [\n",
    "    SVC(gamma=2, C=1),\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(criterion='entropy', oob_score=True, n_jobs=-1, random_state= 0),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(n_estimators=100),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for clf in tqdm(classifiers, unit='Model') :\n",
    "    clf.fit(X_train_trans, y_train)\n",
    "    \n",
    "    name = str(clf).split('(')[0]\n",
    "    \n",
    "    results[name] = {\n",
    "        \"train_score\" : clf.score(X_train_trans, y_train),  \n",
    "        \"valid_score\" : clf.score(X_valid_trans, y_valid)\n",
    "    }      \n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 2)\n",
    "clf =  RandomForestClassifier(criterion='entropy', oob_score=True, n_jobs=-1, random_state= 0)\n",
    "rf_param_grid = {\n",
    "    'max_depth': [25, 30],\n",
    "    'min_samples_leaf': [10, 15, 16],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'n_estimators': [50, 100, 150]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(estimator=clf, cv=tscv, param_grid=rf_param_grid)\n",
    "search.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.score(X_train_trans, y_train), search.score(X_valid_trans, y_valid)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = X_train.shape[0]\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "clf_parameters = {\n",
    "    'criterion': 'entropy',\n",
    "    'min_samples_leaf': 15,\n",
    "    'max_depth' : 25,\n",
    "     'min_samples_split': 8,\n",
    "    'oob_score': True,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 0}\n",
    "\n",
    "n_trees_l = [75, 100, 150, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "valid_score = []\n",
    "oob_score = []\n",
    "feature_importances = []\n",
    "\n",
    "for n_trees in tqdm(n_trees_l, desc='Training Models', unit='Model'):\n",
    "    \n",
    "    clf = RandomForestClassifier(**search.best_params_)\n",
    "    clf.fit(X_train_trans, y_train)\n",
    "    \n",
    "    train_score.append(clf.score(X_train_trans, y_train))\n",
    "    valid_score.append(clf.score(X_valid_trans, y_valid))\n",
    "    \n",
    "#     oob_score.append(clf.oob_score_)\n",
    "#     feature_importances.append(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score, valid_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(xs, ys, labels, title='', x_label='', y_label=''):\n",
    "    for x, y, label in zip(xs, ys, labels):\n",
    "        plt.ylim((0.3, 0.9))\n",
    "        plt.plot(x, y, label=label)\n",
    "        \n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0)\n",
    "    plt.show()\n",
    "\n",
    "plot([n_trees_l]*3,\n",
    "    [train_score, valid_score, oob_score],\n",
    "    ['train', 'validation', 'oob'],\n",
    "    'Random Forrest Accuracy',\n",
    "    'Number of Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_array=[-1,1]\n",
    "alpha_score = clf.predict_proba(X_train_trans).dot(np.array(prob_array))\n",
    "\n",
    "# calculate daily returns\n",
    "alpha_return = alpha_score * data.loc[X_train.index, 'target'].shift(-1) \n",
    "\n",
    "xau_usd_return = data.loc[X_train.index, 'target']\n",
    "\n",
    "# calculate cumulative performance\n",
    "alpha_perf = 100000 * ((1 + alpha_return).cumprod())\n",
    "xau_usd_per = 100000 * ((1 + xau_usd_return).cumprod())\n",
    "\n",
    "#alpha_return.plot()\n",
    "alpha_sharpe = (np.sqrt(252.) * alpha_return.mean()) / alpha_return.std() \n",
    "xau_usd_sharpe = (np.sqrt(252.) * xau_usd_return.mean()) / xau_usd_return.std() \n",
    "\n",
    "alpha_perf.plot()\n",
    "xau_usd_per.plot()\n",
    "\n",
    "xau_usd_return.mean() / alpha_return.mean() \n",
    "sns.set(rc={'figure.figsize':(15, 8)})\n",
    "plt.legend(labels = ['Model', 'Actual Gold/USD'])\n",
    "\n",
    "\n",
    "print(alpha_sharpe, xau_usd_sharpe)\n",
    "alpha_return.std() / xau_usd_return.std()\n",
    "\n",
    "alpha_perf[-2] ** (252 / alpha_perf.size) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes=np.linspace(.1, 1.0, 5)\n",
    "estimator = RandomForestClassifier(**search.best_params_)\n",
    "cv = TimeSeriesSplit(n_splits = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "plot_learning_curve(estimator, \"lol\", X, y, n_jobs =4, cv =cv, train_sizes=train_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_curve(\n",
    "        #estimator, X, y, cv=cv, n_jobs=4, train_sizes=train_sizes)\n",
    "    \n",
    "cv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
